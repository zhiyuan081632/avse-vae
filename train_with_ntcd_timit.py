#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ NTCD-TIMIT æ•°æ®é›†è®­ç»ƒ VAE æ¨¡å‹çš„ç¤ºä¾‹è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ TCD_TIMIT.py åŠ è½½æ•°æ®
"""

import torch
import torch.nn as nn
from torch.utils import data
from torch import optim
import os
from pathlib import Path

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from TCD_TIMIT import TIMIT
from AV_VAE import myVAE
from pytorchtools import EarlyStopping

def get_file_list(data_dir):
    """
    è·å–æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰ WAV æ–‡ä»¶çš„è·¯å¾„åˆ—è¡¨
    
    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
    
    Returns:
        WAV æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    file_list = []
    data_path = Path(data_dir)
    
    if not data_path.exists():
        raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
    
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ .wav æ–‡ä»¶
    for wav_file in data_path.rglob('*.wav'):
        file_list.append(str(wav_file.absolute()))
    
    file_list.sort()
    
    print(f"åœ¨ {data_dir} ä¸­æ‰¾åˆ° {len(file_list)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    
    return file_list


def train_vae_with_ntcd_timit(quick_test=False):
    """
    ä½¿ç”¨ NTCD-TIMIT æ•°æ®é›†è®­ç»ƒ VAE æ¨¡å‹
    
    Args:
        quick_test: å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨è¾ƒå°çš„ batch_size å’Œ epochs
    """
    
    print("=" * 80)
    if quick_test:
        print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼ - ä½¿ç”¨ NTCD-TIMIT æ•°æ®é›†è®­ç»ƒ VAE æ¨¡å‹")
    else:
        print("ä½¿ç”¨ NTCD-TIMIT æ•°æ®é›†è®­ç»ƒ VAE æ¨¡å‹")
    print("=" * 80)
    
    # ========== 1. è®¾ç½®è·¯å¾„ ==========
    
    # æ•°æ®æ ¹ç›®å½• (é€šè¿‡ prepare_ntcd_timit_data.py å‡†å¤‡)
    base_dir = Path('/mnt/d/data/NTCD-TIMIT/avse')
    
    # è®­ç»ƒå’ŒéªŒè¯æ•°æ®ç›®å½•
    data_dir_tr = base_dir / 'training' / 'speech'
    data_dir_val = base_dir / 'validation' / 'speech'
    
    print(f"\nè®­ç»ƒæ•°æ®ç›®å½•: {data_dir_tr}")
    print(f"éªŒè¯æ•°æ®ç›®å½•: {data_dir_val}")
    
    # ========== 2. è·å–æ–‡ä»¶åˆ—è¡¨ ==========
    
    print("\n" + "=" * 80)
    print("åŠ è½½æ•°æ®æ–‡ä»¶åˆ—è¡¨...")
    print("=" * 80)
    
    try:
        file_list_tr = get_file_list(data_dir_tr)
        file_list_val = get_file_list(data_dir_val)
    except FileNotFoundError as e:
        print(f"\né”™è¯¯: {e}")
        print("\nè¯·å…ˆè¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬:")
        print("  python prepare_ntcd_timit_data.py --noise_type Clean --speaker_type volunteers")
        return
    
    if len(file_list_tr) == 0:
        print("\né”™è¯¯: è®­ç»ƒæ•°æ®ä¸ºç©ºï¼Œè¯·å…ˆå‡†å¤‡æ•°æ®")
        return
    
    if len(file_list_val) == 0:
        print("\nè­¦å‘Š: éªŒè¯æ•°æ®ä¸ºç©º")
    
    print(f"\nè®­ç»ƒé›†æ–‡ä»¶æ•°: {len(file_list_tr)}")
    print(f"éªŒè¯é›†æ–‡ä»¶æ•°: {len(file_list_val)}")
    print(f"\nç¬¬ä¸€ä¸ªè®­ç»ƒæ–‡ä»¶: {file_list_tr[0]}")
    if file_list_val:
        print(f"ç¬¬ä¸€ä¸ªéªŒè¯æ–‡ä»¶: {file_list_val[0]}")
    
    # ========== 3. STFT å‚æ•° ==========
    
    wlen_sec = 64e-3      # STFT çª—å£é•¿åº¦ 64ms
    hop_percent = 0.521   # è·³è·ƒæ¯”ä¾‹ 52.1%
    fs = 16000           # é‡‡æ ·ç‡ 16kHz
    zp_percent = 0       # é›¶å¡«å……æ¯”ä¾‹
    trim = False         # æ˜¯å¦ä¿®å‰ªé™éŸ³
    verbose = False
    
    # ========== 4. ç½‘ç»œå‚æ•° ==========
    
    input_dim = 513              # STFT é¢‘ç‚¹æ•° (nfft/2 + 1)
    latent_dim = 32             # æ½œåœ¨ç©ºé—´ç»´åº¦
    hidden_dim_encoder = [128]  # ç¼–ç å™¨éšè—å±‚ç»´åº¦
    activation = torch.tanh     # éŸ³é¢‘å±‚æ¿€æ´»å‡½æ•°
    activationv = nn.ReLU()     # è§†é¢‘å±‚æ¿€æ´»å‡½æ•°
    
    # ========== 5. è®­ç»ƒå‚æ•° ==========
    
    if quick_test:
        # å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šå°æ‰¹æ¬¡ã€å°‘è½®æ•°
        batch_size = 32
        epochs = 5
        print(f"\nğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼š")
        print(f"   batch_size = {batch_size} (å‡å°ä»¥åŠ å¿«è®­ç»ƒ)")
        print(f"   epochs = {epochs} (å‡å°‘ä»¥å¿«é€ŸéªŒè¯)")
    else:
        # æ­£å¸¸è®­ç»ƒæ¨¡å¼
        batch_size = 128
        epochs = 50  # æ¼”ç¤ºç”¨ï¼Œå®é™…è®­ç»ƒå¯è®¾ç½®ä¸º 200
    
    lr = 1e-4
    num_workers = 0
    shuffle_file_list = True
    shuffle_samples_in_batch = True
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # ========== 6. åˆ›å»ºæ•°æ®åŠ è½½å™¨ ==========
    
    print("\n" + "=" * 80)
    print("åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    print("=" * 80)
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†
    # video_part=False è¡¨ç¤ºä¸ä½¿ç”¨è§†é¢‘æ•°æ®ï¼ˆçº¯éŸ³é¢‘è®­ç»ƒï¼‰
    train_dataset = TIMIT(
        data_mode='training',
        file_list=file_list_tr,
        wlen_sec=wlen_sec,
        hop_percent=hop_percent,
        fs=fs,
        zp_percent=zp_percent,
        trim=trim,
        verbose=verbose,
        batch_size=batch_size,
        shuffle_file_list=shuffle_file_list,
        video_part=True  # è®¾ç½®ä¸º True è¡¨ç¤ºä½¿ç”¨éŸ³é¢‘å’Œè§†é¢‘
    )
    
    train_dataloader = data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=shuffle_samples_in_batch,
        num_workers=num_workers
    )
    
    print(f"è®­ç»ƒæ•°æ®é›†å¤§å°: {len(train_dataset)} å¸§")
    print(f"æ³¨æ„: video_part=Falseï¼Œè§†é¢‘è¾“å…¥å°†ä½¿ç”¨éŸ³é¢‘æ•°æ®å‰¯æœ¬")
    
    # åˆ›å»ºéªŒè¯æ•°æ®é›†
    if file_list_val:
        val_dataset = TIMIT(
            data_mode='validation',
            file_list=file_list_val,
            wlen_sec=wlen_sec,
            hop_percent=hop_percent,
            fs=fs,
            zp_percent=zp_percent,
            trim=trim,
            verbose=verbose,
            batch_size=batch_size,
            shuffle_file_list=shuffle_file_list,
            video_part=False
        )
        
        val_dataloader = data.DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=shuffle_samples_in_batch,
            num_workers=num_workers
        )
        
        print(f"éªŒè¯æ•°æ®é›†å¤§å°: {len(val_dataset)} å¸§")
    else:
        val_dataloader = None
    
    print(f"\nâš ï¸  é‡è¦: å½“å‰ä¸ºéŸ³è§†é¢‘è”åˆæ¨¡å¼ (video_part=True)")
    print(f"   æ¨¡å‹å°†ä½¿ç”¨è§†é¢‘ä¿¡æ¯è¿›è¡Œè”åˆè®­ç»ƒ (blockVenc=0.0, blockVdec=0.0)")
    
    # ========== 7. åˆ›å»ºæ¨¡å‹ ==========
    
    print("\n" + "=" * 80)
    print("åˆ›å»º VAE æ¨¡å‹...")
    print("=" * 80)
    
    # blockVenc=0.0, blockVdec=0.0 è¡¨ç¤ºå¯ç”¨è§†é¢‘è·¯å¾„ï¼ŒéŸ³è§†é¢‘è”åˆè®­ç»ƒ
    vae = myVAE(
        input_dim=input_dim,
        latent_dim=latent_dim,
        hidden_dim_encoder=hidden_dim_encoder,
        activation=activation,
        activationv=activationv,
        blockZ=0.0,      # 0=ä½¿ç”¨æ½œåœ¨å˜é‡ z
        blockVenc=0.0,   # 0=å¯ç”¨ç¼–ç å™¨è§†é¢‘è·¯å¾„
        blockVdec=0.0,   # 0=å¯ç”¨è§£ç å™¨è§†é¢‘è·¯å¾„
        x_block=0.0,
        landmarks_dim=4489  # è§†é¢‘ç‰¹å¾ç»´åº¦ (67x67=4489)
    ).to(device)
    
    print(f"æ¨¡å‹å‚æ•°:")
    print(f"  è¾“å…¥ç»´åº¦: {input_dim}")
    print(f"  æ½œåœ¨ç»´åº¦: {latent_dim}")
    print(f"  éšè—å±‚ç»´åº¦: {hidden_dim_encoder}")
    print(f"  è§†é¢‘ç‰¹å¾ç»´åº¦: 4489 (67x67)")
    print(f"  éŸ³è§†é¢‘è”åˆè®­ç»ƒ: blockVenc=0.0, blockVdec=0.0")
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(vae.parameters(), lr=lr)
    
    # æŸå¤±å‡½æ•°
    def loss_function(recon_xi, xi, mui, logvari):
        # é‡æ„æŸå¤±ï¼ˆè´Ÿå¯¹æ•°ä¼¼ç„¶ï¼‰
        recon = torch.sum(torch.log(recon_xi) + xi / recon_xi)
        # KL æ•£åº¦
        KLD = -0.5 * torch.sum(logvari - mui.pow(2) - logvari.exp())
        return recon + KLD
    
    # ========== 8. è®­ç»ƒå¾ªç¯ ==========
    
    print("\n" + "=" * 80)
    print("å¼€å§‹è®­ç»ƒ...")
    print("=" * 80)
    
    # Early Stopping
    save_dir = base_dir / 'saved_model'
    save_dir.mkdir(exist_ok=True)
    
    if quick_test:
        checkpoint_path = save_dir / 'ntcd_timit_quicktest_checkpoint.pt'
        early_stopping = EarlyStopping(save_dir=str(checkpoint_path), patience=3)  # å‡å° patience
    else:
        checkpoint_path = save_dir / 'ntcd_timit_checkpoint.pt'
        early_stopping = EarlyStopping(save_dir=str(checkpoint_path), patience=10)
    
    for epoch in range(epochs):
        # è®­ç»ƒæ¨¡å¼
        vae.train()
        train_losses = []
        
        for batch_idx, (batch_audio, batch_video) in enumerate(train_dataloader):
            batch_audio = batch_audio.to(device)
            batch_video = batch_video.to(device)
            
            # å‰å‘ä¼ æ’­
            recon_batch, mu, logvar = vae(batch_audio, batch_video)
            loss = loss_function(recon_batch, batch_audio, mu, logvar)
            
            train_losses.append(loss.item())
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            # æ¯ 10 ä¸ª batch æ‰“å°ä¸€æ¬¡
            if batch_idx % 10 == 0:
                print(f"Epoch [{epoch+1}/{epochs}] Batch [{batch_idx}/{len(train_dataloader)}] "
                      f"Loss: {loss.item():.4f}")
        
        # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
        train_loss = sum(train_losses) / len(train_dataset)
        
        # éªŒè¯
        if val_dataloader is not None:
            vae.eval()
            valid_losses = []
            
            with torch.no_grad():
                for batch_audio, batch_video in val_dataloader:
                    batch_audio = batch_audio.to(device)
                    batch_video = batch_video.to(device)
                    
                    recon_batch, mu, logvar = vae(batch_audio, batch_video)
                    loss = loss_function(recon_batch, batch_audio, mu, logvar)
                    valid_losses.append(loss.item())
            
            valid_loss = sum(valid_losses) / len(val_dataset)
        else:
            valid_loss = train_loss
        
        # æ‰“å°ç»Ÿè®¡
        print(f"\n====> Epoch: [{epoch+1}/{epochs}] "
              f"train_loss: {train_loss:.5f} "
              f"valid_loss: {valid_loss:.5f}\n")
        
        # Early stopping
        early_stopping(train_loss, valid_loss, vae, epoch, optimizer)
        
        if early_stopping.early_stop:
            print("Early stopping è§¦å‘ï¼Œåœæ­¢è®­ç»ƒ")
            break
    
    # ========== 9. ä¿å­˜æœ€ç»ˆæ¨¡å‹ ==========
    
    if quick_test:
        final_model_path = save_dir / 'final_model_ntcd_timit_quicktest.pt'
    else:
        final_model_path = save_dir / 'final_model_ntcd_timit.pt'
    
    torch.save(vae.state_dict(), final_model_path)
    
    print("\n" + "=" * 80)
    print("è®­ç»ƒå®Œæˆï¼")
    print("=" * 80)
    print(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
    print(f"æœ€ä½³æ£€æŸ¥ç‚¹: {checkpoint_path}")


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='ä½¿ç”¨ NTCD-TIMIT æ•°æ®é›†è®­ç»ƒ VAE æ¨¡å‹')
    parser.add_argument('--quick_test', action='store_true',
                        help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨å°æ‰¹æ¬¡(32)å’Œå°‘è½®æ•°(5)å¿«é€ŸéªŒè¯è®­ç»ƒæµç¨‹')
    
    args = parser.parse_args()
    
    train_vae_with_ntcd_timit(quick_test=args.quick_test)
